import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

from .Model import Model


class Internlm(Model):
    def __init__(self, config):
        super().__init__(config)
        self.tokenizer = AutoTokenizer.from_pretrained(self.name, trust_remote_code=True,
                                                  device_map="auto")
        self.model = AutoModelForCausalLM.from_pretrained(self.name, trust_remote_code=True,
                                                     device_map="auto", torch_dtype=torch.float16)
        self.model = self.model.eval()

    def query(self, msg):
        result, _ = self.model.chat(self.tokenizer, msg, history=[])
        return result
    